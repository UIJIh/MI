{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: The weather is nice today.\n",
      "Candidate 1: '오늘 날씨가 좋다.' -> Similarity: 0.9465\n",
      "Candidate 2: '오늘은 비가 온다.' -> Similarity: 0.8983\n",
      "Candidate 3: '날씨가 흐리다.' -> Similarity: 0.9103\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import XLMRobertaModel, XLMRobertaTokenizer\n",
    "\n",
    "# 1. 모델 및 토크나이저 로드\n",
    "model_name = \"microsoft/infoxlm-base\"\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
    "model = XLMRobertaModel.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 2. 토크나이징 및 벡터 추출 함수\n",
    "def tokenize_and_embed(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :]  # [CLS] 벡터 반환\n",
    "\n",
    "# 3. 유사도 계산 함수\n",
    "def calculate_similarity(query, candidates):\n",
    "    query_embedding = tokenize_and_embed([query])\n",
    "    candidate_embeddings = tokenize_and_embed(candidates)\n",
    "    \n",
    "    similarities = F.cosine_similarity(query_embedding, candidate_embeddings, dim=-1)\n",
    "    return similarities.cpu().numpy()\n",
    "\n",
    "# 4. Inference 실행\n",
    "inference_data = {\n",
    "    \"source\": \"The weather is nice today.\",\n",
    "    \"candidates\": [\"오늘 날씨가 좋다.\", \"오늘은 비가 온다.\", \"날씨가 흐리다.\"]\n",
    "}\n",
    "\n",
    "# 유사도 계산\n",
    "source = inference_data[\"source\"]\n",
    "candidates = inference_data[\"candidates\"]\n",
    "\n",
    "similarities = calculate_similarity(source, candidates)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Source: {source}\")\n",
    "for i, candidate in enumerate(candidates):\n",
    "    print(f\"Candidate {i+1}: '{candidate}' -> Similarity: {similarities[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Pair Similarities:\n",
      "'The weather is nice today.' <-> 'It is raining heavily outside.' -> Similarity: 0.8854\n",
      "'The weather is nice today.' <-> 'I love programming.' -> Similarity: 0.8408\n",
      "'The weather is nice today.' <-> 'The cat is sleeping on the couch.' -> Similarity: 0.8127\n",
      "'The weather is nice today.' <-> 'The sun is shining brightly.' -> Similarity: 0.8779\n",
      "'It is raining heavily outside.' <-> 'The weather is nice today.' -> Similarity: 0.8854\n",
      "'It is raining heavily outside.' <-> 'I love programming.' -> Similarity: 0.8174\n",
      "'It is raining heavily outside.' <-> 'The cat is sleeping on the couch.' -> Similarity: 0.8058\n",
      "'It is raining heavily outside.' <-> 'The sun is shining brightly.' -> Similarity: 0.8751\n",
      "'I love programming.' <-> 'The weather is nice today.' -> Similarity: 0.8408\n",
      "'I love programming.' <-> 'It is raining heavily outside.' -> Similarity: 0.8174\n",
      "'I love programming.' <-> 'The cat is sleeping on the couch.' -> Similarity: 0.8612\n",
      "'I love programming.' <-> 'The sun is shining brightly.' -> Similarity: 0.8217\n",
      "'The cat is sleeping on the couch.' <-> 'The weather is nice today.' -> Similarity: 0.8127\n",
      "'The cat is sleeping on the couch.' <-> 'It is raining heavily outside.' -> Similarity: 0.8058\n",
      "'The cat is sleeping on the couch.' <-> 'I love programming.' -> Similarity: 0.8612\n",
      "'The cat is sleeping on the couch.' <-> 'The sun is shining brightly.' -> Similarity: 0.8049\n",
      "'The sun is shining brightly.' <-> 'The weather is nice today.' -> Similarity: 0.8779\n",
      "'The sun is shining brightly.' <-> 'It is raining heavily outside.' -> Similarity: 0.8751\n",
      "'The sun is shining brightly.' <-> 'I love programming.' -> Similarity: 0.8217\n",
      "'The sun is shining brightly.' <-> 'The cat is sleeping on the couch.' -> Similarity: 0.8049\n"
     ]
    }
   ],
   "source": [
    "english_sentences = [\n",
    "    \"The weather is nice today.\",\n",
    "    \"It is raining heavily outside.\",\n",
    "    \"I love programming.\",\n",
    "    \"The cat is sleeping on the couch.\",\n",
    "    \"The sun is shining brightly.\"\n",
    "]\n",
    "\n",
    "# 문장 페어 생성 (모든 문장을 서로 비교)\n",
    "sentence_pairs = [(s1, s2) for i, s1 in enumerate(english_sentences) for j, s2 in enumerate(english_sentences) if i != j]\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import XLMRobertaModel, XLMRobertaTokenizer\n",
    "\n",
    "# 1. 모델 및 토크나이저 로드\n",
    "model_name = \"microsoft/infoxlm-base\"\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
    "model = XLMRobertaModel.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 2. 토크나이징 및 벡터 추출 \n",
    "def tokenize_and_embed(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :]  # [CLS] 벡터 반환\n",
    "\n",
    "# 3. 유사도 계산 \n",
    "def calculate_similarity(sentence_pairs):\n",
    "    similarities = []\n",
    "    for s1, s2 in sentence_pairs:\n",
    "        s1_embedding = tokenize_and_embed([s1])\n",
    "        s2_embedding = tokenize_and_embed([s2])\n",
    "        similarity = F.cosine_similarity(s1_embedding, s2_embedding, dim=-1).item()\n",
    "        similarities.append((s1, s2, similarity))\n",
    "    return similarities\n",
    "similarities = calculate_similarity(sentence_pairs)\n",
    "\n",
    "print(\"Sentence Pair Similarities:\")\n",
    "for s1, s2, sim in similarities:\n",
    "    print(f\"'{s1}' <-> '{s2}' -> Similarity: {sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Idiom뿐만 아니라 그냥 general dataset 혹은 pretrained-dataset 가지고 contrastive learning 적용하기\n",
    "2. 다른 방법..? \n",
    "3. 그리고 ranking model에 reference는 그냥 hypotheis로?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
