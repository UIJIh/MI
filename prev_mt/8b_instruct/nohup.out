nohup: ignoring input
Downloading shards:   0%|          | 0/30 [00:00<?, ?it/s]Downloading shards:   3%|‚ñé         | 1/30 [00:00<00:15,  1.92it/s]Downloading shards:   7%|‚ñã         | 2/30 [00:00<00:13,  2.05it/s]Downloading shards:  10%|‚ñà         | 3/30 [00:01<00:12,  2.20it/s]Downloading shards:  13%|‚ñà‚ñé        | 4/30 [00:01<00:11,  2.25it/s]Downloading shards:  17%|‚ñà‚ñã        | 5/30 [00:02<00:10,  2.30it/s]Downloading shards:  20%|‚ñà‚ñà        | 6/30 [00:02<00:10,  2.21it/s]Downloading shards:  23%|‚ñà‚ñà‚ñé       | 7/30 [00:03<00:10,  2.20it/s]Downloading shards:  27%|‚ñà‚ñà‚ñã       | 8/30 [00:03<00:10,  2.20it/s]Downloading shards:  30%|‚ñà‚ñà‚ñà       | 9/30 [00:04<00:09,  2.25it/s]Downloading shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 10/30 [00:04<00:09,  2.18it/s]Downloading shards:  37%|‚ñà‚ñà‚ñà‚ñã      | 11/30 [00:04<00:08,  2.21it/s]Downloading shards:  40%|‚ñà‚ñà‚ñà‚ñà      | 12/30 [00:05<00:08,  2.23it/s]Downloading shards:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 13/30 [00:05<00:07,  2.14it/s]Downloading shards:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 14/30 [00:06<00:07,  2.18it/s]Downloading shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 15/30 [00:06<00:06,  2.16it/s]Downloading shards:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 16/30 [00:07<00:06,  2.16it/s]Downloading shards:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 17/30 [00:07<00:05,  2.23it/s]Downloading shards:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 18/30 [00:08<00:05,  2.17it/s]Downloading shards:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 19/30 [00:08<00:04,  2.20it/s]Downloading shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 20/30 [00:09<00:04,  2.17it/s]Downloading shards:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 21/30 [00:09<00:04,  2.21it/s]Downloading shards:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 22/30 [00:10<00:04,  1.90it/s]Downloading shards:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 23/30 [00:10<00:03,  1.90it/s]Downloading shards:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 24/30 [00:11<00:03,  1.99it/s]Downloading shards:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 25/30 [00:11<00:02,  2.02it/s]Downloading shards:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 26/30 [00:12<00:02,  1.97it/s]Downloading shards:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 27/30 [00:12<00:01,  1.86it/s]Downloading shards:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 28/30 [00:13<00:01,  1.99it/s]Downloading shards:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 29/30 [00:13<00:00,  1.96it/s]Downloading shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:14<00:00,  2.00it/s]Downloading shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:14<00:00,  2.10it/s]
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|‚ñé         | 1/30 [00:11<05:43, 11.83s/it]Loading checkpoint shards:   7%|‚ñã         | 2/30 [00:24<05:37, 12.06s/it]Loading checkpoint shards:  10%|‚ñà         | 3/30 [00:36<05:30, 12.24s/it]Loading checkpoint shards:  13%|‚ñà‚ñé        | 4/30 [00:49<05:25, 12.53s/it]Loading checkpoint shards:  17%|‚ñà‚ñã        | 5/30 [01:01<05:10, 12.42s/it]Loading checkpoint shards:  20%|‚ñà‚ñà        | 6/30 [01:13<04:55, 12.31s/it]Loading checkpoint shards:  23%|‚ñà‚ñà‚ñé       | 7/30 [01:25<04:41, 12.24s/it]Loading checkpoint shards:  27%|‚ñà‚ñà‚ñã       | 8/30 [01:38<04:32, 12.40s/it]Loading checkpoint shards:  30%|‚ñà‚ñà‚ñà       | 9/30 [01:51<04:22, 12.48s/it]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 10/30 [02:03<04:06, 12.31s/it]Loading checkpoint shards:  37%|‚ñà‚ñà‚ñà‚ñã      | 11/30 [02:15<03:53, 12.28s/it]Loading checkpoint shards:  40%|‚ñà‚ñà‚ñà‚ñà      | 12/30 [02:27<03:39, 12.22s/it]Loading checkpoint shards:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 13/30 [02:40<03:31, 12.46s/it]Loading checkpoint shards:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 14/30 [02:53<03:21, 12.61s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 15/30 [03:05<03:06, 12.41s/it]Loading checkpoint shards:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 16/30 [03:17<02:53, 12.40s/it]Loading checkpoint shards:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 17/30 [03:29<02:38, 12.23s/it]Loading checkpoint shards:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 18/30 [03:42<02:29, 12.48s/it]Loading checkpoint shards:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 19/30 [03:55<02:18, 12.57s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 20/30 [04:07<02:04, 12.44s/it]Loading checkpoint shards:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 21/30 [04:19<01:50, 12.33s/it]Loading checkpoint shards:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 22/30 [04:32<01:38, 12.35s/it]Loading checkpoint shards:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 23/30 [04:45<01:27, 12.56s/it]Loading checkpoint shards:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 24/30 [04:57<01:15, 12.64s/it]Loading checkpoint shards:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 25/30 [05:10<01:02, 12.50s/it]Loading checkpoint shards:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 26/30 [05:22<00:49, 12.40s/it]Loading checkpoint shards:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 27/30 [05:34<00:36, 12.26s/it]Loading checkpoint shards:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 28/30 [05:46<00:24, 12.37s/it]Loading checkpoint shards:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 29/30 [05:59<00:12, 12.42s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [06:04<00:00, 10.35s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [06:04<00:00, 12.16s/it]
  0%|          | 0/15676 [00:00<?, ?it/s]  0%|          | 1/15676 [00:00<33:29,  7.80it/s]  9%|‚ñâ         | 1450/15676 [00:00<00:01, 7638.73it/s] 19%|‚ñà‚ñä        | 2908/15676 [00:00<00:01, 10619.23it/s] 28%|‚ñà‚ñà‚ñä       | 4372/15676 [00:00<00:00, 12145.82it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 5838/15676 [00:00<00:00, 13029.26it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 7173/15676 [00:00<00:00, 12987.92it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 8638/15676 [00:00<00:00, 13518.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 10101/15676 [00:00<00:00, 13865.84it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 11563/15676 [00:00<00:00, 14097.89it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 13024/15676 [00:01<00:00, 14251.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 14484/15676 [00:01<00:00, 14357.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15676/15676 [00:01<00:00, 12826.87it/s]
Processed 15676 conversations.
Sample: 
{'text': "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nIn simple words, what does the idiom 'pie in the sky' mean?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nThe meaning of 'pie in the sky' is: something that is unrealistic or unlikely to happen<|eot_id|>"}
/data/uijih/anaconda3/envs/python3.11.3/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.

Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.
  warnings.warn(message, FutureWarning)
/data/uijih/anaconda3/envs/python3.11.3/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.
  warnings.warn(
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 1 examples [00:01,  1.62s/ examples]Generating train split: 373 examples [00:01, 302.53 examples/s]Generating train split: 755 examples [00:01, 667.77 examples/s]Generating train split: 1238 examples [00:03, 447.05 examples/s]Generating train split: 1593 examples [00:03, 645.66 examples/s]Generating train split: 1924 examples [00:04, 459.51 examples/s]Generating train split: 2189 examples [00:04, 556.76 examples/s]Generating train split: 2453 examples [00:04, 700.06 examples/s]Generating train split: 2686 examples [00:05, 776.11 examples/s]Generating train split: 2686 examples [00:05, 525.19 examples/s]
Vocab before resize: 128256
Vocab after resize: 128256
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: Currently logged in as: uiji (uijis). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.9
wandb: Run data is saved locally in /data/uijih/8b_instruct/wandb/run-20250102_165710-jldr15e3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ./model_output/llama70_sft_idioms-NEW-2-post
wandb: ‚≠êÔ∏è View project at https://wandb.ai/uijis/huggingface
wandb: üöÄ View run at https://wandb.ai/uijis/huggingface/runs/jldr15e3
  0%|          | 0/10 [00:00<?, ?it/s]/data/uijih/anaconda3/envs/python3.11.3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/data/uijih/anaconda3/envs/python3.11.3/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 10%|‚ñà         | 1/10 [54:00<8:06:02, 3240.25s/it]                                                  {'loss': 2.8746, 'grad_norm': 0.6273508667945862, 'learning_rate': 1.9510565162951538e-05, 'epoch': 0.1}
 10%|‚ñà         | 1/10 [54:00<8:06:02, 3240.25s/it] 20%|‚ñà‚ñà        | 2/10 [1:48:03<7:12:16, 3242.06s/it]                                                    {'loss': 2.8409, 'grad_norm': 0.6908731460571289, 'learning_rate': 1.8090169943749477e-05, 'epoch': 0.19}
 20%|‚ñà‚ñà        | 2/10 [1:48:03<7:12:16, 3242.06s/it] 30%|‚ñà‚ñà‚ñà       | 3/10 [2:42:06<6:18:16, 3242.29s/it]                                                    {'loss': 2.7995, 'grad_norm': 0.6739832758903503, 'learning_rate': 1.5877852522924733e-05, 'epoch': 0.29}
 30%|‚ñà‚ñà‚ñà       | 3/10 [2:42:06<6:18:16, 3242.29s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [3:36:09<5:24:15, 3242.66s/it]                                                    {'loss': 2.8125, 'grad_norm': 0.6510862708091736, 'learning_rate': 1.3090169943749475e-05, 'epoch': 0.38}
 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [3:36:09<5:24:15, 3242.66s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [4:30:14<4:30:17, 3243.57s/it]                                                    {'loss': 2.7915, 'grad_norm': 0.5350261926651001, 'learning_rate': 1e-05, 'epoch': 0.48}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [4:30:14<4:30:17, 3243.57s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [5:24:20<3:36:18, 3244.50s/it]                                                    {'loss': 2.7532, 'grad_norm': 0.6134006381034851, 'learning_rate': 6.909830056250527e-06, 'epoch': 0.57}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [5:24:20<3:36:18, 3244.50s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [6:18:27<2:42:15, 3245.14s/it]                                                    {'loss': 2.7535, 'grad_norm': 0.61468106508255, 'learning_rate': 4.12214747707527e-06, 'epoch': 0.67}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [6:18:27<2:42:15, 3245.14s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [7:12:34<1:48:11, 3245.79s/it]                                                    {'loss': 2.739, 'grad_norm': 0.6678445339202881, 'learning_rate': 1.9098300562505266e-06, 'epoch': 0.76}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [7:12:34<1:48:11, 3245.79s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [8:06:41<54:06, 3246.03s/it]                                                    {'loss': 2.7312, 'grad_norm': 0.8745293021202087, 'learning_rate': 4.894348370484648e-07, 'epoch': 0.86}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [8:06:41<54:06, 3246.03s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [9:00:47<00:00, 3246.23s/it]                                                   {'loss': 2.7277, 'grad_norm': 0.6802794337272644, 'learning_rate': 0.0, 'epoch': 0.95}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [9:00:47<00:00, 3246.23s/it]                                                   {'train_runtime': 32459.8358, 'train_samples_per_second': 0.083, 'train_steps_per_second': 0.0, 'train_loss': 2.782355213165283, 'epoch': 0.95}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [9:00:47<00:00, 3246.23s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [9:00:47<00:00, 3244.78s/it]
!!! SAVED TO './model_output/llama70_sft_idioms-NEW-2-post' !!!
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.027 MB uploadedwandb: | 0.027 MB of 0.027 MB uploadedwandb: 
wandb: Run history:
wandb:         train/epoch ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:   train/global_step ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:     train/grad_norm ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÑ
wandb: train/learning_rate ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:          train/loss ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:               total_flos 5.486556794899661e+17
wandb:              train/epoch 0.95238
wandb:        train/global_step 10
wandb:          train/grad_norm 0.68028
wandb:      train/learning_rate 0.0
wandb:               train/loss 2.7277
wandb:               train_loss 2.78236
wandb:            train_runtime 32459.8358
wandb: train_samples_per_second 0.083
wandb:   train_steps_per_second 0.0
wandb: 
wandb: üöÄ View run ./model_output/llama70_sft_idioms-NEW-2-post at: https://wandb.ai/uijis/huggingface/runs/jldr15e3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/uijis/huggingface
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250102_165710-jldr15e3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
